{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea5b633-fdec-4f22-b191-cf84baba1f77",
   "metadata": {},
   "source": [
    "# 24. Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc69ac-6975-4ed1-a395-6ff01d9a05e5",
   "metadata": {},
   "source": [
    "**What is Cost Function:**\n",
    "- A cost function is an important parameter that determines how well a machine learning model performs for a given dataset\n",
    "- Cost function is a measure of how wrong the model is in estimating the relationship b/w x(input) and y(ouput) parameter.\n",
    "- With the help of cost function, you draw best fit line\n",
    "- Cost function and loss functions are both functions of error - to make the error minmum from the best fit line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3d2e6-d90b-42b4-a9d2-06b8b79d8f60",
   "metadata": {},
   "source": [
    "**Types of cost function:**\n",
    "- Regression cost function\n",
    "- Classification cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a17c7c-5849-4207-8874-f3d498eb274a",
   "metadata": {},
   "source": [
    "**1) Regression Cost Function:**\n",
    "- Regression models are used to make a prediction for the continuous variables.\n",
    "1) MSE (Mean Square Error)\n",
    "2) RMSE (Root Mean Square Error)\n",
    "3) MAE (Mean Absolute Error)\n",
    "4) R^2 Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66033e9-663e-454c-bcd5-95b8186979c4",
   "metadata": {},
   "source": [
    "**2) Binary Classification Cost Function:**\n",
    "Classification models are used to make predictions of categorical variables, such as predicitions for 0 or 1, cat or dog, etc.\n",
    "\n",
    "**3) Multi-class Classification Cost Function:**\n",
    "A multi-class classification cost function is used in the classification problems for which instances are allocated to one of more than two classes.\n",
    "Binary Cross Entropy Cost Function or Log Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350b2a7-b463-47b8-b9cb-743ff1de9b76",
   "metadata": {},
   "source": [
    "## 24.1 Regression Cost Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5522d-b161-4d94-b802-67028718860b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5db6fc-91d6-4b06-ba92-acb0986595d6",
   "metadata": {},
   "source": [
    "<img src=\"Images/regression-cost-fucntion.jpg\"  style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be224e62-8612-4f29-8f86-303d629999f4",
   "metadata": {},
   "source": [
    "- red line represents prediction line\n",
    "- blue points represent original data\n",
    "- red triangles represent error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0b717-9c16-4caf-aaad-b8d61a8c0770",
   "metadata": {},
   "source": [
    "- please note that the error value should be minimum\n",
    "- For this we use **cost function to make the error minimum from prediction line**\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5e6a7-ac4c-461a-b8d0-ebd353af0ecb",
   "metadata": {},
   "source": [
    "## 24.2 Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227778af-d1a4-42f0-9d21-12c9ea5b9818",
   "metadata": {},
   "source": [
    "**Mean Sqaure Error (MSE)** is the mean squared difference b/w the actual and predicted values. MSE penalizes high errors caused by outliers by squaring the error. MSE is also known as **L2 Loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a9b7f-72a6-4a97-978a-ffeffc159600",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) is calculated as:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "$$\n",
    "Where as:\n",
    "- y_i  = Original value\n",
    "- \\hat{y_i} = Predicted value\n",
    "- n = number of rows\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c546eb0-d36c-42c7-a349-658cbe8f44fb",
   "metadata": {},
   "source": [
    "Advantages of using MSE are:\n",
    "1) It is defferentiable\n",
    "\n",
    "Disadvantages of using MSE:\n",
    "1) When outlier is present in data, it will increase exponentially when squaring took place, so it will give wrong predictions\n",
    "2) The data does not remain in original form, rather available in sqaured form, and also if original data is in cm. then it will change the unit in cm^2 as well. So the data as well as units will not be in original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6f6f3-413a-43a4-9d08-aefed9070ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0d48ba6-bbb4-4254-be96-afcdcab5979f",
   "metadata": {},
   "source": [
    "The differentiation of \\( y = mx + c \\) with respect to \\( x \\) is:\n",
    "$$\n",
    "\\frac{d}{dx}(y) = \\frac{d}{dx}(mx + c) = m\n",
    "$$\n",
    "\n",
    "In this differentiation:\n",
    "\n",
    "- \\( \\frac{d}{dx}(y) \\) represents the derivative of \\( y \\) with respect to \\( x \\).\n",
    "- \\( \\frac{d}{dx}(mx + c) \\) is the derivative of the function \\( mx + c \\).\n",
    "- The result \\( m \\) is the slope of the line, which is constant in this linear equation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a813ca-dd6a-4dcc-8f0e-3f9d0fecf499",
   "metadata": {},
   "source": [
    "The update formula for finding **m(new)** is given by:\n",
    "$$\n",
    "M_{\\text{new}} = M_{\\text{old}} - \\lambda \\left(\\frac{dz}{dm}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576df6a-5b3b-48ce-8ce7-42dfc94096a0",
   "metadata": {},
   "source": [
    "## 24.3 Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b695ff-2940-4460-88de-73677e549957",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE)** is the mean absolute difference b/w the actual values and the predicted values. \n",
    "MAE is more robut to outliers. the insensitivity to outliers is b/c it does not penalize high errors caused by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707ab46-889d-438a-830f-56eb2ce6815a",
   "metadata": {},
   "source": [
    "The Mean Absolute Error (MAE) is calculated as:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9097b9ef-2f69-4ab0-8857-d0a270502602",
   "metadata": {},
   "source": [
    "Advatages of MAE:\n",
    "1) Error remains in original form\n",
    "2) It treats outlier well\n",
    "\n",
    "Disadvantages are:\n",
    "1) This is not differentiable equation, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b249c-2812-4362-bb25-978cd3c6f0ff",
   "metadata": {},
   "source": [
    "## 24.4 Root Mean Sqaured Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533512a-18d0-4aaf-9041-e951e923c95e",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error (RMSE)** is the root sqaured mean of the difference b/w actual and predicted values.\n",
    "RMSE can be used in situations where we want to penalize high errors but not as much as MSE does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900eb44-801c-478a-b73d-57bc4138b2d7",
   "metadata": {},
   "source": [
    "The Root Mean Square Error (RMSE) is calculated as:\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36974a-0eca-4e6e-9c3f-f31f1dbc0f87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eb06677-cbbb-400c-b909-31445ba8c340",
   "metadata": {},
   "source": [
    "## 24.5 How to Find Best Fit Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baab3c9-33bb-4555-9afe-fa4f488bdce8",
   "metadata": {},
   "source": [
    " - For finding best line:\n",
    "1) Keep the error (loss) minimum (Which will be calculated through cost function)\n",
    "2) Thorugh quardratic equation, gradient descent, we take the minimum value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a848f6-3874-48d8-b77f-a7dc6e19a3db",
   "metadata": {},
   "source": [
    "<img src=\"Images/gradient-descent-in-machine-learning1.png\"  style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8413789-832c-4479-b2f6-c83eacb42755",
   "metadata": {},
   "source": [
    "<img src=\"Images/gradient-descent-in-machine-learning2.jpg\"  style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71aa44-8e92-4660-9c39-33cfce9e49f7",
   "metadata": {},
   "source": [
    "- loss function will be minimum after looking for best m (slope) and c (intercept) values in y = mx + c\n",
    "- m: donates angle\n",
    "- c: donates intercept at y-axis.\n",
    "- this whole process is called gradient descent technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7498cc-7590-4629-ac94-bfe4811f0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
