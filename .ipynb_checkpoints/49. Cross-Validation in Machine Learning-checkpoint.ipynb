{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf64260-4eba-4fa0-b1ee-20677c023402",
   "metadata": {},
   "source": [
    "# 49. Cross-Validation in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8974418-f5a7-41eb-a6be-1f7390e9a722",
   "metadata": {},
   "source": [
    "- It gives the information about how long your model can give you highest accuracy on particular data\n",
    "- Cross-validation is a technique for validating the model efficiency by training it on the subset of input data and testing on previously unseen subset of the input data\n",
    "- It will give the range which will tell that your data has how much min accuracy and max accuracy it can attain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c72bd-72df-4321-9136-5bdac870102c",
   "metadata": {},
   "source": [
    "<img src=\"Images/model-validation.jpg\"  style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16629a-54d2-4300-8f25-5736a5347111",
   "metadata": {},
   "source": [
    "## 49.1 Methods used for cross-validation:\n",
    "- Leave p out cross-validation\n",
    "- Leave one out cross-validation\n",
    "- Holdout cross-validation\n",
    "- Repeated random subsampling validation\n",
    "- k-fold cross-validation\n",
    "- Stratified k-fold cross-validation\n",
    "- Time Series cross-validation\n",
    "- Nested cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae52b3b-0e4c-4a0d-afa5-42b94e6888e2",
   "metadata": {},
   "source": [
    "### 49.1.1 K-Fold Cross-Validation:\n",
    "- The original dataset is equally partitioned into k subparts or folds.\n",
    "- Out of the k-folds or groups, for each iteration, one group is selected as validation data,\n",
    "- and the remaining (k-1) groups are selected as training data.\n",
    "- Not suitable for an imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902c7c3-2eec-4165-b288-7ba7be350710",
   "metadata": {},
   "source": [
    "### 49.1.2 Stratified Cross-Validation:\n",
    "- It works when the data is in classification nature\n",
    "- It works on unbalanced data\n",
    "- The original dataset is equally partitioned into k subparts or folds.\n",
    "- Out of the k-folds or groups, for each iteration, one group is selected as validation data,\n",
    "- and the remaining (k-1) groups are selected as training data.\n",
    "- Stratified k-fold cross-validation solved the problem of imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9188cb-2d98-4a6c-b22f-9522a8eac537",
   "metadata": {},
   "source": [
    "### 49.1.3 Leave-One-Out Cross-Validation:\n",
    "- It gets trained on whole data\n",
    "- It is an exhaustive cross-validation technique\n",
    "- it is a category of Lp OCV with the case of p=1.\n",
    "- It is slower in case of large data b/c of this issue it is used less\n",
    "- The model trained by this method is very accurate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b140abb-d50b-47a4-862b-7ee9e07e7289",
   "metadata": {},
   "source": [
    "### 49.1.4 Leave-P-Out Cross-Validation:\n",
    "- It is an exhaustive cross-validation technique, that involves using p-obervation as validation data\n",
    "- It is slower in case of large data b/c of this issue it is used less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8593562-3ae7-4a76-9d86-d4783ad9b150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
