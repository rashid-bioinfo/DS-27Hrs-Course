{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ef1e71-abe4-4114-872c-da7aae75cc74",
   "metadata": {},
   "source": [
    "# 32. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bbbd1-32ce-473f-bf51-7c5ba9918136",
   "metadata": {},
   "source": [
    "- Confusion Matrix is to model the difference b/w the output data generated from testing of a model and the output of the original data. i.e. matrix b/w predicted output and original output.\n",
    "- Model with 90%, 95% or even 100% can give wrong predictions\n",
    "- The problem with wrong predictions can be traced through **confusion matrix**\n",
    "- Confusion matrix gives better analysis of the built model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828cc2f-9cde-4531-ba5f-034d2dff7713",
   "metadata": {},
   "source": [
    "- A confusion matrix is a simple and useful tool for understanding the performance of a classification model, like one used in machine learning or statistics.\n",
    "- It helps you evaluate how well your model is doing in categorizing things correctly.\n",
    "- It is also know as the **error matrix / evaluation matrix**.\n",
    "- The matrix consists of predictions result in a summarized from, which has number of correct predictions and incorrect predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16076af6-b63f-47b0-ae8b-837467c3068c",
   "metadata": {},
   "source": [
    "<img src=\"Images/confusion-matrix.jpg\"  style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf9181-34a7-4c8b-9aba-f819d4a52dd8",
   "metadata": {},
   "source": [
    "**Interpretation of graphs**\n",
    "\n",
    "- TN = True Negative = Actual: 0, Predicted: 0 -> **True Negative** \n",
    "- FN = False Negative =  Actual: 1, Predicted: 0 -> **False Negative** \n",
    "- FP = False Positive = Actual: 0, Predicted: 1 -> **False Positive**\n",
    "- TP = True Positive = Actual: 1, Predicted: 1 -> **True Positive**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397df453-a0c2-4387-85dd-778fa73a344e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Model Accuracy} = \\frac{TN + TP}{TN + TP + FN + FP}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d505a4-4be9-4b47-82dc-ed83a224c11e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Model Error} = \\frac{FN + FP}{TN + TP + FN + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7b54f-00d3-418f-8743-7b86d738a764",
   "metadata": {},
   "source": [
    "**False Negative**: The model has predicted no (0), but the actual value was yes (1), it is also called as **Type-II error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795694d3-9d81-4fc9-abef-1fa45ad9ecee",
   "metadata": {},
   "source": [
    "**False Positive**: The model has predicted yes (1), but the actual value was no (0), it is also called as **Type-I error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5a4cd-844a-4baf-bf68-8886039e1b7b",
   "metadata": {},
   "source": [
    "- **False Negative is more dangerous**, depends on the situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d30af-542b-4f3a-9d0a-5746fb13ed7a",
   "metadata": {},
   "source": [
    "- if false negative is upto 5%, then reject this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08381ff8-7d68-4117-9998-50b8c013042d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baf2c309-9f73-4c78-b59f-b3f454b9bcc3",
   "metadata": {},
   "source": [
    "## 32.1 Confusion Matrix (Sensitivity, Precision, Recall, F1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724eb41-4074-422a-825e-199ad09a8517",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92187c1b-9285-4081-b871-28cbf740e567",
   "metadata": {},
   "source": [
    "**Precision:** It helps us to measure the ability to classify positive samples in the model.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b739c87-5eb3-47cf-84f7-695ffd977d5e",
   "metadata": {},
   "source": [
    "- To increase the recall, False Positive value should be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890e9b6-4fbe-4b25-a6a7-11d14266b4c7",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9ba71-c37f-4390-a359-8a21b0665ff7",
   "metadata": {},
   "source": [
    "**Recall:** It helps us to measure how many positive samples were correctly classified by the ML model.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a38ad-6dab-4a09-9b9d-efcd0a94c89f",
   "metadata": {},
   "source": [
    "- To increase the recall, False Negative value should be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1ab3d-b8d3-4b3f-b39e-d55b844e0a90",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b31bcd-ba85-482d-a6f3-be8d301fcfc5",
   "metadata": {},
   "source": [
    "- when we donot have information because of lack of knowledge in domain to whether improve Precsion or/and recall, then we will use **F1 Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90843c65-713c-4911-957a-c1e4fed91493",
   "metadata": {},
   "source": [
    "- It is the harmonic mean of precision and recall. It takes false positive and false negative into account.\n",
    "- Therefore, it performs well on an imbalanced dataset.\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2*\\frac{Precision * Recall}{Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eeee46-77e1-428d-bbde-ed5de7422b90",
   "metadata": {},
   "source": [
    "- Should increase the value of F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e00086-6da2-4440-afe6-eda576ac4d90",
   "metadata": {},
   "source": [
    "In Confusion matix, \n",
    "- Precsion should should be high\n",
    "- Recall should be high\n",
    "- F-Score should be high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb3de4-39ed-476a-a53f-21621dd7b637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
